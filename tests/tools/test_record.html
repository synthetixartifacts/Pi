<!DOCTYPE html>
<html>
<head>
    <title>Audio Recording Test</title>
    <style>
        body { font-family: monospace; background: #000; color: #0f0; padding: 20px; }
        button { margin: 10px; padding: 10px; }
        #status { margin: 20px 0; }
        #volume { height: 20px; background: #333; margin: 10px 0; }
        #volumeBar { height: 100%; background: #0f0; width: 0%; transition: width 0.1s; }
    </style>
</head>
<body>
    <h1>Audio Recording Test</h1>
    <button id="start">Start Recording</button>
    <button id="stop" disabled>Stop Recording</button>
    <button id="download" disabled>Download Recording</button>
    <button id="testSTT" disabled>Test STT</button>
    
    <div id="volume"><div id="volumeBar"></div></div>
    <div id="status">Ready</div>
    <audio id="playback" controls style="display:none; margin: 20px 0;"></audio>
    <pre id="result"></pre>

    <script>
        let mediaRecorder;
        let chunks = [];
        let audioContext;
        let analyser;
        let recordedBlob;
        let volumeInterval;

        document.getElementById('start').onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    } 
                });
                
                // Setup volume monitoring
                audioContext = new AudioContext();
                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                analyser.fftSize = 256;
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                volumeInterval = setInterval(() => {
                    analyser.getByteFrequencyData(dataArray);
                    const avg = dataArray.reduce((a, b) => a + b) / bufferLength;
                    document.getElementById('volumeBar').style.width = (avg / 255 * 100) + '%';
                }, 100);
                
                chunks = [];
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                
                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) chunks.push(e.data);
                };
                
                mediaRecorder.onstop = () => {
                    clearInterval(volumeInterval);
                    document.getElementById('volumeBar').style.width = '0%';
                    
                    recordedBlob = new Blob(chunks, { type: 'audio/webm' });
                    const url = URL.createObjectURL(recordedBlob);
                    
                    const audio = document.getElementById('playback');
                    audio.src = url;
                    audio.style.display = 'block';
                    
                    document.getElementById('download').disabled = false;
                    document.getElementById('testSTT').disabled = false;
                    document.getElementById('status').textContent = `Recorded: ${(recordedBlob.size / 1024).toFixed(1)} KB`;
                };
                
                mediaRecorder.start();
                document.getElementById('status').textContent = 'Recording... (speak clearly into microphone)';
                document.getElementById('start').disabled = true;
                document.getElementById('stop').disabled = false;
                
            } catch (err) {
                document.getElementById('status').textContent = 'Error: ' + err.message;
            }
        };
        
        document.getElementById('stop').onclick = () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                document.getElementById('start').disabled = false;
                document.getElementById('stop').disabled = true;
            }
        };
        
        document.getElementById('download').onclick = () => {
            const a = document.createElement('a');
            a.href = URL.createObjectURL(recordedBlob);
            a.download = 'recording.webm';
            a.click();
        };
        
        document.getElementById('testSTT').onclick = async () => {
            if (!recordedBlob) return;
            
            document.getElementById('result').textContent = 'Testing STT...';
            
            const formData = new FormData();
            formData.append('file', recordedBlob, 'audio.webm');
            formData.append('model', 'small.en');
            
            try {
                const response = await fetch('/api/stt/v1/audio/transcriptions', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                document.getElementById('result').textContent = 'STT Result:\n' + JSON.stringify(result, null, 2);
                
                if (result.text) {
                    document.getElementById('status').textContent = 'Transcription: ' + result.text;
                }
            } catch (err) {
                document.getElementById('result').textContent = 'Error: ' + err.message;
            }
        };
    </script>
</body>
</html>